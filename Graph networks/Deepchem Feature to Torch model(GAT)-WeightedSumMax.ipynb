{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1e949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Y-8874903-E.ESTUDIANT\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import torch\n",
    "from deepchem.models import GCNModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "709ed067",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(r\"Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cacdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c385988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = data.SMILES.to_list()\n",
    "labels = data.LABELS.to_list()\n",
    "        \n",
    "featurizer = dc.feat.MolGraphConvFeaturizer() ## Feature calculator\n",
    "        \n",
    "X = featurizer.featurize(smiles)\n",
    "        \n",
    "dataset = dc.data.NumpyDataset(X=X, y=labels)\n",
    "        \n",
    "torch_data = dataset.make_pytorch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66af17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e104294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,root,transform=None,pre_transform=None,pre_filter=None):\n",
    "        \n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        If this file exists in raw_dir, the download is not triggered\n",
    "        \"\"\"\n",
    "        return \"data.csv\"\n",
    "        \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "    \n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        self.data = pd.read_csv(self.raw_paths[0])\n",
    "        smiles = self.data.SMILES.to_list()\n",
    "        labels = self.data.LABELS.to_list()\n",
    "        \n",
    "        featurizer = dc.feat.MolGraphConvFeaturizer() ## Feature calculator\n",
    "        \n",
    "        X = featurizer.featurize(smiles)\n",
    "        \n",
    "        j=0\n",
    "        for idx, Gdata in tqdm(enumerate(X)):\n",
    "            \n",
    "            pyG_data = Gdata\n",
    "            \n",
    "            nodes = torch.tensor(pyG_data.node_features,dtype= torch.float32)\n",
    "            \n",
    "            Edge_index = torch.tensor(pyG_data.edge_index,dtype= torch.int64 )\n",
    "            #Edge_feats = torch.tensor(pyG_data.edge_features,dtype=torch.float32)\n",
    "            y = torch.tensor([labels[idx]],dtype= torch.float32 )\n",
    "            ### create data object\n",
    "            data = Data(x=nodes,edge_index=Edge_index,y=y,smiles=smiles[idx])\n",
    "            torch.save(data,os.path.join(self.processed_dir,f\"data_{j}.pt\"))\n",
    "            j+=1\n",
    "            \n",
    "    def len (self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def get(self,idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir,f'data_{idx}.pt'))\n",
    "        return data\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28324db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "3330it [00:02, 1366.47it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = BBBDataset(root=\".\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d4cf314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "### Splitting of data\n",
    "train_set, valid_set = random_split(dataset,[2331,999])\n",
    "trainloader = DataLoader(train_set,shuffle=True,batch_size=512)\n",
    "validloader = DataLoader(valid_set, shuffle=True,batch_size=512)\n",
    "# testloader = DataLoader(test_set, shuffle=True,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab5b50",
   "metadata": {},
   "source": [
    "## Applying PyGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64102cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2cf78294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import WeightAndSum\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GlobalAttention,GATConv\n",
    "from torch_geometric.nn import global_add_pool,global_max_pool\n",
    "from torch.nn import Sequential\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "43e80c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSumMax(nn.Module):\n",
    "    \"\"\" Pooling layer\"\"\"\n",
    "    \n",
    "    def __init__(self,n_feats):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_feats = n_feats\n",
    "        self.atom_weights = nn.Sequential(nn.Linear(n_feats, 1),\n",
    "                                          nn.Sigmoid())\n",
    "        \n",
    "    def forward(self,x,batch):\n",
    "        expanded_index = batch.unsqueeze(-1).expand(x.size())\n",
    "        weights = self.atom_weights(x)\n",
    "        weighted_feats = x*weights\n",
    "\n",
    "        \n",
    "        ## Loop to calculated weighted Sum\n",
    "        prev_ind = 0\n",
    "        expanded_data = []\n",
    "        for i in Counter(pd.DataFrame(expanded_index)[0]).values(): ## features is 30 that's why last index is taken\n",
    "            j = prev_ind + i\n",
    "            extracted = torch.tensor(weighted_feats[prev_ind:j,:]) ## x replaced with weighted_feats\n",
    "            summed = torch.sum(extracted,axis=0,keepdim=True) ## features of each nodes summed up\n",
    "            maxed,index = torch.max(extracted,dim=0,keepdim=True) ## selecting the max \n",
    "            weighted= torch.cat([summed,maxed],dim=1) ## concating both\n",
    "            expanded_data.append(weighted)\n",
    "            prev_ind = prev_ind + i  \n",
    "        \n",
    "            _feats = torch.vstack(expanded_data)\n",
    "        return _feats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "413273dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self,in_feats,out_feats,n_heads=1,concat=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.heads = n_heads\n",
    "        \n",
    "        ### Graph Layer\n",
    "        self.GAT_conv = GATConv(in_channels=self.in_feats,out_channels=self.out_feats,\n",
    "                                heads= self.heads,concat=concat,)\n",
    "        \n",
    "    \n",
    "        ## Initiating Residual connection\n",
    "        self.res_connection = nn.Linear(self.in_feats,self.out_feats*self.heads)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,edge_index):\n",
    "        \n",
    "        new_feats = self.GAT_conv(x,edge_index)\n",
    "        res_feats = F.relu(self.res_connection(x))\n",
    "        new_feats = new_feats + res_feats\n",
    "        new_feats =   F.dropout(input=new_feats,p=0.6,training=self.training) ## Dropout in each layer\n",
    "        \n",
    "        return new_feats\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8d604798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import global_mean_pool,global_max_pool\n",
    "from collections import Counter\n",
    "\n",
    "class PyGAT(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        GAT layer with 3 attention head for each node.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ## Graph attention layer\n",
    "        self.GAT_Conv1 = GATLayer(in_feats= 30,out_feats= 64,n_heads= 3,concat=True)\n",
    "        self.GAT_Conv2 = GATLayer(in_feats= 192, out_feats= 16,n_heads = 1,)\n",
    "        \n",
    "        \n",
    "        ## Pooling Layer\n",
    "        self.weighted = WeightedSumMax(16) ## weighted SumAndMax\n",
    "        \n",
    "        \n",
    "        ## Predictor Layer\n",
    "        self.predict = nn.Sequential(\n",
    "                        nn.Dropout(p=0.6,),\n",
    "                        nn.Linear(16, 128),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm1d(128),\n",
    "                        nn.Linear(128, 1)\n",
    "                                        )\n",
    "        \n",
    "    \n",
    "                 \n",
    "    def forward(self,data):\n",
    "        \n",
    "        ### Extracting data from batch\n",
    "        batch, x, edge_index, edge_attr = (data.batch, data.x, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        ### Stacking Layer\n",
    "        x = self.GAT_Conv1(x=x,edge_index=edge_index)\n",
    "        x = self.GAT_Conv2(x=x,edge_index=edge_index)\n",
    "        \n",
    "        x = global_max_pool(x,batch) ## Changed\n",
    "#       x = self.weighted(x,batch) ## weighted sum\n",
    "#       x = self.GlobalAtt(x,batch)\n",
    "    \n",
    "            \n",
    "        ## Final predictor layer\n",
    "        x = F.sigmoid(self.predict(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f8baa5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyGAT(\n",
       "  (GAT_Conv1): GATLayer(\n",
       "    (GAT_conv): GATConv(30, 64, heads=3)\n",
       "    (res_connection): Linear(in_features=30, out_features=192, bias=True)\n",
       "  )\n",
       "  (GAT_Conv2): GATLayer(\n",
       "    (GAT_conv): GATConv(192, 16, heads=1)\n",
       "    (res_connection): Linear(in_features=192, out_features=16, bias=True)\n",
       "  )\n",
       "  (weighted): WeightedSumMax(\n",
       "    (atom_weights): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (predict): Sequential(\n",
       "    (0): Dropout(p=0.6, inplace=False)\n",
       "    (1): Linear(in_features=16, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import BCEWithLogitsLoss, BCELoss,CrossEntropyLoss, Softmax\n",
    "\n",
    "## Intilaize Network\n",
    "net = PyGAT()\n",
    "\n",
    "### initialize an optimizer with someparameters\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001,)\n",
    "\n",
    "### Defining loss\n",
    "criterion = BCELoss()\n",
    "\n",
    "### criterion\n",
    "#criterion.cuda()\n",
    "\n",
    "## shifting to GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device=\"cpu\"\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "560611ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def accuracy_counter(y_prob,y_true):\n",
    "    \n",
    "    y_prob = np.array(y_prob)\n",
    "    y_prob = np.where(y_prob <= 0.5, 0, y_prob)\n",
    "    y_prob = np.where(y_prob > 0.5, 1, y_prob)\n",
    "    accuracy = accuracy_score(np.array(y_true),y_prob)\n",
    "    \n",
    "    return (accuracy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "87037e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    net.train()\n",
    "    y_true = []\n",
    "    proab = []\n",
    "    train_loss = []\n",
    "    for data in trainloader:## Iterate in batches over training dataset\n",
    "        data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() ## clear gradients\n",
    "        out = net(data).squeeze(0) ## single forward pass\n",
    "        \n",
    "        proab.extend(out.detach().cpu().numpy().squeeze().tolist()) ## appending to list each batch\n",
    "        y_true.extend(data.y.unsqueeze(1).squeeze().tolist()) ## appending true value of each batch\n",
    "        \n",
    "        loss = criterion(out,data.y.unsqueeze(1)) ## compute the loss\n",
    "        \n",
    "        train_loss.append(loss)\n",
    "        \n",
    "        loss.backward() ## Derive gradients\n",
    "        optimizer.step()## update parameters based on gradients\n",
    "        \n",
    "    av_loss = torch.sum(torch.tensor(train_loss))/len(trainloader)\n",
    "    \n",
    "    accuracy = accuracy_counter(proab,y_true)\n",
    "    \n",
    "    return (av_loss,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f2c2c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    net.eval()\n",
    "    y_true = []\n",
    "    proab = []\n",
    "    val_loss = []\n",
    "    for data in loader:## Iterate in batches over training dataset\n",
    "        data.to(device)\n",
    "        out = net(data).squeeze(0) ## single forward pass\n",
    "        \n",
    "        proab.extend(out.detach().cpu().numpy().squeeze().tolist()) ## appending to list each batch\n",
    "        y_true.extend(data.y.unsqueeze(1).squeeze().tolist()) ## appending true value of each batch\n",
    "    \n",
    "        loss = criterion(out,data.y.unsqueeze(1))\n",
    "        val_loss.append(loss)\n",
    "        \n",
    "    val = torch.sum(torch.tensor(val_loss))/len(loader)\n",
    "    accuracy = accuracy_counter(proab,y_true)\n",
    "    return (val,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8a2474af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train loss: 0.5062, Train accuracy: 0.7580, val loss: 0.9426, val accuracy: 0.5856\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Y-8874~1.EST\\AppData\\Local\\Temp/ipykernel_23204/2193329347.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mtrain_loss1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_accuracy1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrain_loss2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_accuracy2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Y-8874~1.EST\\AppData\\Local\\Temp/ipykernel_23204/401948981.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m## Iterate in batches over training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## single forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mproab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## appending to list each batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Y-8874~1.EST\\AppData\\Local\\Temp/ipykernel_23204/1916562785.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m### Stacking Layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGAT_Conv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGAT_Conv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Y-8874~1.EST\\AppData\\Local\\Temp/ipykernel_23204/69590494.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mnew_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGAT_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mres_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mnew_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_feats\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mres_feats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;31m# propagate_type: (x: OptPairTensor, alpha: OptPairTensor, edge_attr: OptTensor)  # noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         out = self.propagate(edge_index, x=x, alpha=alpha, edge_attr=edge_attr,\n\u001b[0m\u001b[0;32m    243\u001b[0m                              size=size)\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msegment_csr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0m\u001b[0;32m    428\u001b[0m                            reduce=self.aggr)\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch_scatter\\scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \"\"\"\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'sum'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'add'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mul'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscatter_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\torch_scatter\\scatter.py\u001b[0m in \u001b[0;36mscatter_sum\u001b[1;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "## Accuracy\n",
    "traine_accuracy = []\n",
    "vale_accuracy = []\n",
    "teste_accuracy = []\n",
    "\n",
    "## Loss\n",
    "epoch_loss = []\n",
    "valida_loss = []\n",
    "test_loss_full = []\n",
    "\n",
    "for epoch in range(1,epochs):\n",
    "    \n",
    "    train_loss1,train_accuracy1 = train()\n",
    "    \n",
    "    train_loss2,train_accuracy2 = test(trainloader)\n",
    "    \n",
    "    val_loss,val_accuracy = test(validloader)\n",
    "    \n",
    "#     test_loss,test_accuracy = test(testloader)\n",
    "    \n",
    "    ##losses\n",
    "    epoch_loss.append(train_loss1)\n",
    "    valida_loss.append(val_loss)\n",
    "#     test_loss_full.append(test_loss)\n",
    "    \n",
    "    ## accuracy\n",
    "    traine_accuracy.append(train_accuracy1[0])\n",
    "    vale_accuracy.append(val_accuracy[0])\n",
    "#     teste_accuracy.append(test_accuracy[0])\n",
    "    \n",
    "    print(f'Epoch: {epoch:03d}, Train loss: {train_loss1:.4f}, Train accuracy: {train_accuracy1[0]:.4f}, val loss: {val_loss:.4f}, val accuracy: {val_accuracy[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cefb2a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (299,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Y-8874~1.EST\\AppData\\Local\\Temp/ipykernel_23204/1375132182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m  \u001b[1;32min\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Train loss\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Red\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalida_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"valid loss\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Green\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#plt.plot([i for i in range(1,epochs)],[i.cpu().detach().numpy() for i in test_loss],label=\"Test loss\",color=\"Blue\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2756\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2757\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2758\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2759\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1630\u001b[0m         \"\"\"\n\u001b[0;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1632\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1633\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    499\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (299,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([i for i in range(1,epochs)],[i.cpu().detach().numpy() for i  in epoch_loss],label=\"Train loss\",color=\"Red\",)\n",
    "plt.plot([i for i in range(1,epochs)],[i.cpu().detach().numpy() for i in valida_loss],label=\"valid loss\",color=\"Green\")\n",
    "#plt.plot([i for i in range(1,epochs)],[i.cpu().detach().numpy() for i in test_loss],label=\"Test loss\",color=\"Blue\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4a0893da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(1,epochs)],[i for i  in traine_accuracy],label=\"Train accuracy\",color=\"Red\",)\n",
    "plt.plot([i for i in range(1,epochs)],[i  for i in vale_accuracy],label=\"valid accuracy\",color=\"Green\")\n",
    "#plt.plot([i for i in range(1,epochs)],[i.cpu().detach().numpy() for i in test_loss],label=\"Test loss\",color=\"Blue\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a78f7e",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5fcd13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,\"model-GCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "20b38ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(\"model-GCN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c942ef9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4506]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval()\n",
    "model1.to(\"cpu\")\n",
    "model1([*testloader][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a3eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
